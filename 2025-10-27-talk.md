# Business Observability: 10-Minute Talk
---

## PRESENTATION PHILOSOPHY 

**Core Principle:** Don't boil the ocean. Show one microflow, demonstrate the art of the possible, then explain how it works.

**Strategy:**
1. **Lead with what's working** (demonstration first, theory second)
2. **Trade bad problems for better problems** (not "more work")
3. **Show the connective tissue** (your role bridges technical health → business outcomes)
4. **Grow the muscle gradually** (not dogma, not mandate, participatory evolution)

---

## SLIDE STRUCTURE & TIMING (7 slides, 10 minutes)

| Slide | Time | Topic | Chuck-Style Element |
|-------|------|-------|---------------------|
| 1 | 1 min | Bridge from Charter + Opening | "Not boiling the ocean, instrumenting one microflow" |
| 2 | 4 min | **DASHBOARD DEMONSTRATION** (Extended) | "Here's what's working - Funding Wire Transfer" |
| 3 | 1.5 min | Three-Person Model (Condensed) | "Clear ownership model, connective tissue concept" |
| 4 | 1.5 min | Onboarding Form (Quick) | "Where business context comes from" |
| 5 | 1 min | Trading Problems Metaphor | "Bad problem → better problem" |
| 6 | 1 min | Reflective Questions | "Where are the gaps in your world?" |
| 7 | 1 min | Call to Engagement | "Grow the muscle together" |

---

## SLIDE 1: BRIDGE FROM CHARTER + OPENING (1 minute)

**[Charter slide has just been shown - Target: December 2025, Champion: Chad Johnson]**

### Visual
Simple transition slide:
```
BUSINESS OBSERVABILITY
Not the north star.
The microflow we instrumented to show what's possible.
```

### Speaker Notes

You just saw the strategic charter—problem statement, I want to show you one microflow we've instrumented—the **Funding Wire Transfer service**—to show you what business observability looks like in your day-to-day work.

**This is focusing on one orchestrated flow to demonstrate the capability.
Before I do, let me frame why this matters to us specifically:

Our teams are triaging alerts every shift. When you get a MIM, what takes longer:
- Figuring out the technical problem?
- Or figuring out **which business stakeholder to notify and what the impact is**?

Business Observability makes that second part explicit. It's **trading a bad problem**—alert noise without business context—**for a better problem**: Which business-aligned signals matter most?

Let me show you what that looks like..."

---

## SLIDE 2: DASHBOARD DEMONSTRATION (4 minutes) — **THE CENTERPIECE**

**[This is THE extended slide where you walk through the dashboard screenshot for 4 minutes]**

### Visual
**Full-screen screenshot** of L3 Service Detail Dashboard for Funding Wire Transfer service:
- Service header showing health status
- Operational signals table with sparklines
- Business impact section

**File Source:** `grafana/grafana-panel-tools/l3-product-service-detail-minimalist-v3-composed.json` (imported to Grafana, screenshot taken)

### Speaker Notes (4-minute walkthrough)

#### Part 1: Service Health at a Glance (60 seconds)

"This is the Service Detail dashboard for the Funding Wire Transfer service. This is what Platform Ops maintains and uses for start-of-day health checks and incident triage.

**First thing you see:** [Point to service header] Service name, business purpose, and current health status.

Notice what's different from traditional monitoring: **Business health is at the top.** Not buried under CPU graphs. Not hidden in technical metrics. Right there: Is this service meeting its business expectation?

This service moves money from loan accounts to customer bank accounts. When it fails, customers don't get funded on time. That's the business outcome we're monitoring."

#### Part 2: Operational Signals (90 seconds)

"Now look at this signals table. [Point to signals panel]

These aren't just technical metrics like 'CPU usage' or 'memory consumption.' These are **business-aligned operational signals:**

- **Wire Transfer Completion Rate**: Are we successfully sending wires?
- **Funding Latency**: How long does it take?
- **Account Validation Success**: Are we catching errors before sending?

Each signal has:
- **Current value** (what's happening right now)
- **Target threshold** (what the business needs)
- **Sparkline** (trend over last 24 hours)
- **Status color** (green/amber/red)

Here's the key insight: **These signals answer the question: Is the business expectation being met?**

Not 'is the server up,' but 'are customers getting funded successfully within our SLI target?'

When you're triaging an alert, this dashboard tells you:
- The technical health (latency, error rates)
- The business outcome (are customers actually blocked?)
- The trend (is this getting worse or recovering?)

That's the **connective tissue** between technical health and business outcomes. You maintain that tissue."

#### Part 3: Business Impact Measurement (90 seconds)

"Now, the most critical part for triage: **Business Impact.** [Point to impact section]

When this service starts failing, these impact signals update in real-time:

- **Customers Blocked**: How many customers can't get funded right now?
- **Revenue at Risk**: What's the dollar exposure?
- **Compliance Cases**: Are we violating funding timelines that have regulatory implications?
- **Operational Load**: How many manual interventions is your team handling?

Here's what's important: **These aren't static text descriptions. These are live signals** that quantify consequence.

When transfer orders fail at 50%, the 'Customers Blocked' signal doesn't stay at zero—it updates to show 47 customers blocked. The 'Revenue at Risk' signal shows actual dollar amounts.

This is what I mean by **trading bad problems for better problems:**

**Bad problem (current state):** Alert fires, you spend 30 minutes in Slack threads figuring out 'How many customers? Which stakeholder? Should I wake someone up?'

**Better problem (with BOS):** Alert fires with business impact explicit. New problem: 'How do we scale this pattern to all our critical services?'

That's a better problem to have."

---

## SLIDE 3: THREE-PERSON MODEL — CONDENSED (1.5 minutes)

### Visual
Three-column layout with **Platform Ops column highlighted**:

```
┌─────────────────────┬─────────────────────┬─────────────────────────┐
│   PRODUCT OWNERS    │     DEVELOPERS      │  PLATFORM OPS (YOU)     │
├─────────────────────┼─────────────────────┼─────────────────────────┤
│ Define business     │ Implement           │ Sustain signals,        │
│ expectations        │ telemetry           │ dashboards, alerts      │
│                     │                     │                         │
│ "95% of wires sent  │ Instrument wire     │ Maintain dashboard      │
│  within 2 hours"    │ completion tracking │ Validate signals firing │
│                     │                     │ Triage using business   │
│                     │                     │ context                 │
└─────────────────────┴─────────────────────┴─────────────────────────┘

Clear ownership model. Each layer essential.
You are the connective tissue.
```

### Speaker Notes

"How does this work? **Clear ownership model with three layers:**

**Product Owners define** the business expectations. Like: 'We need 95% of funding wires sent within 2 hours of loan closing.' They know what the business needs.

**Developers instrument** the telemetry to measure it. They translate that expectation into signals—the code that tracks wire completion rates and timing.

**Platform Ops—that's you—sustains** those signals. You maintain the dashboards. You validate that signals are firing correctly. You use those business-aligned signals during triage to prioritize smarter.

Here's the Chuck Lawton insight: **You are the connective tissue** between technical health metrics and business outcome visibility.

**This isn't new work.** You're already maintaining dashboards and triaging alerts. What changes is the **context** those dashboards provide. Instead of just 'queue depth is high,' you see 'funding wires delayed, blocking customers.'

You're not being asked to define business requirements—that's Product's job. You're not being asked to write instrumentation code—that's Dev's job.

**Your role:** Sustain the operational visibility layer that connects technical health to business outcomes. That's what you already do—we're just making it smarter."

---

## SLIDE 4: ONBOARDING FORM — QUICK (1.5 minutes)

### Visual
**Quick screenshot** of BOS Onboarding form, Step 2 (Stakeholder Expectations)

**File Source:** `bos-platform-ui/deliverables/bos-onboarding-v1.2.0.html` - Step 2 tab

### Speaker Notes

"You might be wondering: Where does that business context come from? How do we know what 'success' means for the Funding Wire Transfer service?

**This is the onboarding form** that Product Owners fill out when a service gets instrumented for business observability.

They define:
- **WHO** cares when this service fails (the stakeholder)
- **WHAT** they expect from the service (the expectation)
- **WHAT HAPPENS** when it doesn't work (the impact)
- **HOW CRITICAL** it is (the priority)

This might look like bureaucracy, but it's actually the source of truth for your alerts and dashboards.

What Product Owners define here **becomes** the signals you monitor, the impact measurements in your dashboard, and the business context in your alerts.

**This is the bridge** from 'Product needs something' to 'Platform Ops monitors it with business context.'

We're working alongside **Chuck Lawton's Value Stream Mapping work** where Product teams are already documenting business flows. Business Observability instruments critical flows identified through that work. Co-creation, not tech hunting for PO time randomly.

Quick, structured, and directly feeds what you maintain."

---

## SLIDE 5: TRADING PROBLEMS METAPHOR (1 minute)

### Visual
Simple two-column comparison:

```
┌──────────────────────────────────┬──────────────────────────────────┐
│     BAD PROBLEM (CURRENT)        │     BETTER PROBLEM (WITH BOS)    │
├──────────────────────────────────┼──────────────────────────────────┤
│                                  │                                  │
│ • Alert volume without priority  │ • Alerts tied to business impact │
│ • 30-min Slack threads figuring  │ • Business context in alert      │
│   out "who cares?"               │   metadata                       │
│ • Handoff confusion between      │ • Documented business context    │
│   US/India shifts                │   visible to both shifts         │
│ • Dashboard shows green while    │ • Business signals surface       │
│   customers are blocked          │   real outcomes                  │
│                                  │                                  │
└──────────────────────────────────┴──────────────────────────────────┘

We're not eliminating problems. We're trading for better ones.
```

### Speaker Notes

"Let me be clear about what Business Observability is and isn't.

**It's NOT:**
- A magic fix that eliminates all problems
- Mandated from leadership
- Extra work on top of your current load

**It IS:**
- **Trading bad problems for better problems**

**Current bad problems:**
- Alert volume without priority context — you investigate everything equally
- 30 minutes every P1 figuring out 'which stakeholder to notify?'
- Shift handoff confusion — US shift learns the business context, India shift has to re-learn it
- Dashboard shows green while customers are actually blocked

**Better problems (with BOS):**
- Alerts tied to business impact — you can triage smarter
- Business context embedded in alert — stakeholder and expectation explicit
- Business context documented in dashboard — visible to both shifts
- Business signals surface real outcomes — if customers are blocked, the dashboard says so

The **new problem**: How do we scale this pattern across all our critical services? How do we grow the muscle of asking 'what business expectation does this signal validate?'

Those are better problems to solve. That's progress."

---

## SLIDE 6: REFLECTIVE QUESTIONS (1 minute)

### Visual
Three questions specific to 24x7 Platform Ops:

```
❓ When you triage a P1 alert today, does the ticket tell you
   which business stakeholder to notify and what expectation is violated?

❓ How many alerts per shift turn out to have zero customer impact—
   but you had to investigate anyway to figure that out?

❓ Think about shift handoffs. How much time does the incoming shift spend
   re-learning the business context the previous shift already discovered?
```

### Speaker Notes

"I want to flip the perspective and ask you some questions. Not expecting answers now—just think about these in your own work:

**First:** When you triage a P1 alert today, does the ticket tell you **which business stakeholder to notify and what expectation is violated?** Or do you have to hunt for that?

**Second:** How many alerts per shift turn out to have **zero customer impact**—but you had to investigate anyway to figure that out? How much time does that waste?

**Third:** Think about shift handoffs between US and India teams. How much time does the incoming shift spend **re-learning the business context** the previous shift already discovered? Is that documented anywhere, or is it tribal knowledge?

These gaps are exactly what Business Observability addresses.

**You're not just keeping systems running. You're validating business outcomes.** That's more meaningful work, and it's a much more strategic conversation with leadership when you can say: 'We reduced triage time by 40% by embedding business context in alerts.'"

---

## SLIDE 7: CALL TO ENGAGEMENT (1 minute)

### Visual
```
GROW THE MUSCLE TOGETHER

✓ This is one microflow (Funding Wire Transfer). Two more in progress
  (Loan Rate Amendment, third candidate). December target: Three flows operational.

✓ Your input shapes how this evolves. Where are we missing business-aligned
  signals? Where do you see dashboards disconnected from real outcomes?

✓ We're building the bridge from current state (alert noise) to future state
  (business-aware monitoring). It's scaffolding, not dogma.

✓ Let's trade our bad problems for better problems, one microflow at a time.

Questions? Let's talk after, or reach me at [contact info]
```

### Speaker Notes

"So where do we go from here?

**First, understand the scope:** This is one microflow—Funding Wire Transfer. We have two more in progress: Loan Rate Amendment flow (co-created with Chuck's Value Stream Mapping work) and a third candidate being selected. **December target: Three flows operational with business observability.**

We're not rolling this out to 387 applications tomorrow. We're instrumenting the **easiest three flows to demonstrate**, proving the pattern works, then scaling from there.

**Second, your input matters.** You're on the front lines of triage and shift handoffs. You see the gaps we don't. Where are we missing business-aligned signals? Where do you maintain dashboards that feel disconnected from real outcomes? **Speak up—that feedback directly shapes how we grow this.**

**Third, think of this as building a bridge.** We're moving from current state (alert noise without business context) to future state (business-aware monitoring). BOS is the **scaffolding** for that bridge. It's not dogma, not mandate—it's **growing the muscle** of asking 'what business expectation does this signal validate?' every time we add monitoring.

**Fourth, the Chuck Lawton philosophy:** We're **trading bad problems for better problems, one microflow at a time.** Show what's possible, then scale the pattern.

Your role in sustaining these signals is critical. This only works if all three layers—Product, Dev, and Platform—align around the same definition of success.

Questions? I'll stick around after, or reach me at [contact info]. **Let's make our monitoring smarter together.**

Thank you."

